try:
	from textNormalization import textNormalization
except:
from common_nlp.textNormalization import textNormalization
from gensim import corpora, models
import subprocess, pickle, pandas as pd

class topicModelling(textNormalization):
	"""Creates topic models for normalized texts"""
	def __init__(self):
		super(topicModelling, self).__init__()
		
	def dicionario_corpora(self,textos):
		return corpora.Dictionary(textos)

	def lda_Model(self, texts, num_topics=5, npasses=20, num_words=15):
		'''O input precisa ser uma lista em que cada elemento da lista Ã© uma string correspondendo a um texto'''
		textos = self.normalize_texts(texts)
		dicionario = self.dicionario_corpora(textos)
		corpus = [dicionario.doc2bow(text) for text in textos]
		return models.ldamodel.LdaModel(corpus, num_topics=num_topics, id2word = dicionario, passes=npasses)

	def topic_to_txt(self, topics, nome_topicos=''):
		for n,top in topics:
			arq = open('wordcloud_topico_'+str(n)+nome_topicos+'.txt','w')
			for t in top.split('+'):
				t = t.strip().replace('"','')
				n_t, word = t.split('*')
				arq.write(int(float(n_t)*10000)*(word+' '))
			subprocess.Popen('wordcloud_cli --text %s --imagefile wordcloud_%s.png --no_collocations' % ('wordcloud_topico_'+str(n)+nome_topicos+'.txt',str(n)+nome_topicos),shell=True)

if __name__ == '__main__':
	dados_1_inst = '/home/ubuntu/topicmodelling/relatorio_cnj_final_1_inst.csv' #texto_decisao
	dados_2_inst = '/home/ubuntu/topicmodelling/relatorio_cnj_final_2_inst_sp.csv' #texto_decisao
	dados_tutela = '/home/ubuntu/topicmodelling/publicacoes_saude.csv'

	def relatorio(path_dados, nome):
		tp = topicModelling()
		df = pd.read_csv(dados_tutela,nrows=10000)
		textos = []
		for index, row in df.iterrows():
			textos.append(row['texto_publicacao'])
		topicos = tp.lda_Model(textos,num_topics=30,num_words=30)
		pickle.dump(topicos,open('topicos_%s.pickle' % (nome,),'wb'))
	
	relatorio(dados_1_inst,'1_instancia')
	relatorio(dados_2_inst,'2_instancia')
	relatorio(dados_tutela,'tutela')